{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Classifiers Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                           \n",
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_curve\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic NLP Processing\n",
    "\n",
    "#### We will define some Python functions that will perform some syntatic work on our corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    return filtered_tokens\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\") + ['year', 'old', 'man', 'woman', 'ap', 'am', 'pm', 'portable', 'pa', 'lat', 'admitting', 'diagnosis', 'lateral']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving our Corpus\n",
    "\n",
    "#### Let's pull in our corpus that we had serialized out to disk.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file = open('classification-corpus.pkl','rb')\n",
    "file = open('corpus.pkl','rb')\n",
    "corpus = pkl.load(file)\n",
    "file.close()\n",
    "corpusList = list(corpus.values())\n",
    "labels = list(corpus.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Document-Term Frequency Counts\n",
    "\n",
    "#### In this step we tokenize our text and remove stop words in addition to generating our frequency counts.\n",
    "\n",
    "#### 1) How many documents are we working with and how many features (unigrams & bigrams)?\n",
    "\n",
    "#### 2) Can you figure out what max_df and min_df is doing to our feature count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True, max_df=0.80, max_features=None, min_df=0.033,\n",
    "                     ngram_range=(1, 2), preprocessor=None, stop_words=cachedStopWords,\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X = cv.fit_transform(corpusList)\n",
    "print(X.shape)\n",
    "print()\n",
    "lexicon = cv.get_feature_names()\n",
    "print (lexicon)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct our Classes\n",
    "\n",
    "#### We need to assign a class for each classification. We typically assign numeric values to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = []\n",
    "for key in corpus:        \n",
    "    if (key.startswith('COPD') or key.startswith('CHF')):\n",
    "        Y.append(0)\n",
    "    elif (key.startswith('PNA')):\n",
    "        Y.append(1)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Run It!\n",
    "\n",
    "#### We will generate models and evaluate the modes using bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truth = []\n",
    "knn_list = [1, 5, 10]\n",
    "knn_prediction= [[],[],[]]\n",
    "linsvm_prediction = []\n",
    "rbfsvm_prediction = []\n",
    "mnb_prediction = []\n",
    "dt_prediction = []\n",
    "bdt_prediction = []\n",
    "rf_prediction = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    print('Interation: ' + str(i+1))\n",
    "    N, D = X.shape\n",
    "    ITB = np.random.choice(N, N, replace=True)\n",
    "    X_ITB = X[ITB, :]\n",
    "    Y_ITB = Y[ITB]\n",
    "    X_OOB = np.delete(X.A, list(set(ITB)), 0)\n",
    "    Y_OOB = np.delete(Y, list(set(ITB)), 0)\n",
    "    N_OOB, D_OOB = X_OOB.shape\n",
    "    truth.append(Y_OOB)\n",
    "    i = 0\n",
    "    for k in knn_list:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k, weights='uniform', algorithm='brute', \n",
    "                                    leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1)\n",
    "        knn.fit(X_ITB, Y_ITB)\n",
    "        Y_hat = knn.predict(X_OOB)\n",
    "        knn_prediction[i].append(Y_hat)\n",
    "        i += 1\n",
    "    linsvm = SVC(C=1.0, gamma='auto', kernel='linear', max_iter=-1, verbose=False)\n",
    "    linsvm.fit(X_ITB, Y_ITB) \n",
    "    Y_hat = linsvm.predict(X_OOB)\n",
    "    linsvm_prediction.append(Y_hat)\n",
    "    rbfsvm = SVC(C=1.0, gamma='auto', kernel='rbf', max_iter=-1, verbose=False)\n",
    "    rbfsvm.fit(X_ITB, Y_ITB) \n",
    "    Y_hat = rbfsvm.predict(X_OOB)\n",
    "    rbfsvm_prediction.append(Y_hat)\n",
    "    mnb = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "    mnb.fit(X_ITB, Y_ITB)\n",
    "    Y_hat = mnb.predict(X_OOB)\n",
    "    mnb_prediction.append(Y_hat)\n",
    "    dt = DecisionTreeClassifier(random_state=0)\n",
    "    dt.fit(X_ITB, Y_ITB)\n",
    "    Y_hat = dt.predict(X_OOB)\n",
    "    dt_prediction.append(Y_hat)\n",
    "    bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=201)\n",
    "    bdt.fit(X_ITB, Y_ITB)\n",
    "    Y_hat = bdt.predict(X_OOB)\n",
    "    bdt_prediction.append(Y_hat)\n",
    "    rf = RandomForestClassifier(n_estimators = 101, oob_score = True, n_jobs = -1, max_features = \"auto\")\n",
    "    rf.fit(X_ITB, Y_ITB)\n",
    "    Y_hat = rf.predict(X_OOB)\n",
    "    rf_prediction.append(Y_hat)\n",
    "\n",
    "\n",
    "truth = np.concatenate(truth, axis=0)    \n",
    "for i in range(0, len(knn_prediction)):\n",
    "    knn_prediction[i] = np.concatenate(knn_prediction[i], axis=0)\n",
    "linsvm_prediction = np.concatenate(linsvm_prediction, axis=0)\n",
    "rbfsvm_prediction = np.concatenate(rbfsvm_prediction, axis=0)\n",
    "mnb_prediction = np.concatenate(mnb_prediction, axis=0)\n",
    "dt_prediction = np.concatenate(dt_prediction, axis=0)\n",
    "bdt_prediction = np.concatenate(bdt_prediction, axis=0)\n",
    "rf_prediction = np.concatenate(rf_prediction, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contingency Tables\n",
    "\n",
    "#### Let's look at the contingency tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(knn_prediction)):\n",
    "    ct = pd.crosstab(knn_prediction[i], truth, margins=True)\n",
    "    ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "    ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "    print('KNN (K = %d)' % knn_list[i])\n",
    "    print(ct)\n",
    "    print()\n",
    "    Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "    Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "    PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "    NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "    ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "    print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "ct = pd.crosstab(linsvm_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "print('Linear SVM')\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n",
    "\n",
    "ct = pd.crosstab(rbfsvm_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "print('RBF Kernel SVM')\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n",
    "\n",
    "ct = pd.crosstab(mnb_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "print('Multinomial Naive Bayes')\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n",
    "\n",
    "ct = pd.crosstab(dt_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "print(\"Decision Tree\")\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n",
    "\n",
    "ct = pd.crosstab(bdt_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Otrher\", \"PNA\", \"Total\"]\n",
    "print(\"Boosting Decision Stumps\")\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n",
    "\n",
    "ct = pd.crosstab(rf_prediction, truth, margins=True)\n",
    "ct.columns = [\"Other\", \"PNA\", \"Total\"]\n",
    "ct.index = [\"Other\", \"PNA\", \"Total\"]\n",
    "print(\"Random Forest\")\n",
    "print(ct)\n",
    "print()\n",
    "Sens = ct.iloc[1][1]/ct.iloc[2][1]\n",
    "Spec = ct.iloc[0][0]/ct.iloc[2][0]\n",
    "PPV = ct.iloc[1][1]/ct.iloc[1][2]\n",
    "NPV = ct.iloc[0][0]/ct.iloc[0][2]\n",
    "ACC = (ct.iloc[0][0] + ct.iloc[1][1]) / ct.iloc[2][2]\n",
    "print(\"Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))\n",
    "print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ROC Curve\n",
    "\n",
    "#### 1) So which classifier do you think is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn1_fpr, knn1_tpr, knn1_thresholds = roc_curve(truth, knn_prediction[0], pos_label=1)\n",
    "knn5_fpr, knn5_tpr, knn5_thresholds = roc_curve(truth, knn_prediction[1], pos_label=1)\n",
    "knn10_fpr, knn10_tpr, knn10_thresholds = roc_curve(truth, knn_prediction[2], pos_label=1)\n",
    "linsvm_fpr, linsvm_tpr, linsvm_thresholds = roc_curve(truth, linsvm_prediction, pos_label=1)\n",
    "rbfsvm_fpr, rbfsvm_tpr, rbfsvm_thresholds = roc_curve(truth, rbfsvm_prediction, pos_label=1)\n",
    "dt_fpr, dt_tpr, dt_thresholds = roc_curve(truth, dt_prediction, pos_label=1)\n",
    "bdt_fpr, bdt_tpr, bdt_thresholds = roc_curve(truth, bdt_prediction, pos_label=1)\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(truth, rf_prediction, pos_label=1)\n",
    "mnb_fpr, mnb_tpr, mnb_thresholds = roc_curve(truth, mnb_prediction, pos_label=1)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(knn1_fpr, knn1_tpr, label='KNN-1')\n",
    "plt.plot(knn5_fpr, knn5_tpr, label='KNN-5')\n",
    "plt.plot(knn10_fpr, knn10_tpr, label='KNN-10')\n",
    "plt.plot(dt_fpr, dt_tpr, label='DecisionTree')\n",
    "plt.plot(bdt_fpr, bdt_tpr, label='BoostingDecisionStumps')\n",
    "plt.plot(rf_fpr, rf_tpr, label='RandomForest')\n",
    "plt.plot(linsvm_fpr, linsvm_tpr, label='Linear SVM')\n",
    "plt.plot(rbfsvm_fpr, rbfsvm_tpr, label='RBF SVM')\n",
    "plt.plot(mnb_fpr, mnb_tpr, label='Multi NB')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
