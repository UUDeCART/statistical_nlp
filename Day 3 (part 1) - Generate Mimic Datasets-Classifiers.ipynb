{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting MIMIC Data\n",
    "\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pymysql\n",
    "import getpass\n",
    "import pickle as pkl\n",
    "from _collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Query List\n",
    "\n",
    "#### Construct a list of queries that we will want to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryList = OrderedDict([('PNA', 'PNA-Mimic.sql'), ('Trauma','Trauma-Mimic.sql')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC Database Connection\n",
    "\n",
    "#### Make a connection to the MIMIC database and get a cursor for record processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host=\"mysql\", \n",
    "                       port = 3306, user=\"jovyan\", \n",
    "                       passwd=getpass.getpass(\"Enter MySQL passwd for jovyan\"), db='mimic2')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve our Data\n",
    "\n",
    "#### For each query we will retrieve the data and build a ordered dictionary containing our data. Were use an ordered dictionary because we want to keep the Pneumonia and Trauma cases together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = OrderedDict()\n",
    "for key in queryList:\n",
    "    count = 1\n",
    "    file = open(queryList[key], 'r')\n",
    "    query = file.read()\n",
    "    print(\"execute query: \" + key)\n",
    "    %time cur.execute(query)\n",
    "    for row in cur:\n",
    "        ckey = key + str(count)\n",
    "        corpus[ckey] = row[0]\n",
    "        count += 1\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safestore the Data\n",
    "\n",
    "#### We will serialize the ordered dictionary structure out to disk. This waty we will not have to rebuild this data structure when we want to use our data. It is a convenience thing...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open('classification-corpus.pkl','wb')\n",
    "pkl.dump(corpus, file)\n",
    "file.close()\n",
    "conn.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
